<div align= "center">
    <h1> ğŸ¦™Llama2-ChineseğŸ¦™ </h1>
</div>

è¿™ä¸ªé¡¹ç›®æ—¨åœ¨æ„å»º**å¼€æºã€å¤§è§„æ¨¡ã€é«˜è´¨é‡**çš„é¢„è®­ç»ƒ/æŒ‡ä»¤è°ƒæ•´SFT/é¢†åŸŸå‚ç›´/RLHFæ•°æ®ï¼Œè¿›ä¸€æ­¥å¢å¼ºLlama2å¤§æ¨¡å‹çš„ä¸­æ–‡èƒ½åŠ›ä»¥åŠæ‰“é€ å¤šç§å‚ç›´é¢†åŸŸæ¨¡å‹ã€‚æˆ‘ä»¬æä¾›æ•°æ®é›†ã€ç›¸åº”çš„è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬ï¼Œä»¥åŠç»è¿‡å¾®è°ƒçš„å¼ºå¤§æ¨¡å‹Llama2-Chineseã€‚

è¿™ä¸ªå·¥ä½œçš„ç‹¬ç‰¹ä¹‹å¤„
- **ä¸­æ–‡åŒ–åªæ˜¯å¼€å§‹**ï¼šLlama2ä¸­æ–‡åŒ–åªæ˜¯ç¬¬ä¸€æ­¥ï¼æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åœ¨Llama2-ChineseåŸºç¡€ä¸ŠæŒç»­åŠ å¼ºæ•°å­¦èƒ½åŠ›&æ’ä»¶è°ƒç”¨èƒ½åŠ›ã€‚
- **å¼€æºä¸é€æ˜**ï¼šé‡‡ç”¨å¼€æºçš„é¢„è®­ç»ƒæ•°æ®ã€æŒ‡ä»¤å¾®è°ƒæ•°æ®ã€ä»¥åŠRLHFæ•°æ®ï¼Œè‡´åŠ›äºæ„å»ºå¯å¤ç°çš„ã€é€æ˜çš„ç ”ç©¶ç”Ÿæ€ã€‚
- **ä¸€ç«™å¼è®­ç»ƒæ–¹æ³•**ï¼šå®ç°äºŒæ¬¡é¢„è®­ç»ƒï¼Œè¯è¡¨æ‰©å……ï¼ŒLoRA / QLoRAå¾®è°ƒï¼Œå…¨å‚æ•°æŒ‡ä»¤å¾®è°ƒï¼Œå¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚

## ğŸš€ æ›´æ–°æ—¥å¿—

- [2023.08.18] [Llama2-13b-Chinese-chat](https://huggingface.co/carlAIwarts/Llama2-13b-Chinese-chat)å‘å¸ƒğŸ‰ğŸ‰ğŸ‰ğŸ‰ï¼›é‡‡ç”¨ä¸­è‹±æ–‡å¼€æºæŒ‡ä»¤å¾®è°ƒæ•°æ®
â³ **Llama2-7b-Chinese-chat**: Llama2-7b-Chinese-chatæ­£åœ¨é£å¥”è€Œæ¥ï¼
â³ **Llama2-Chinese**: ä½¿ç”¨ä¸­è‹±æ–‡è¯­æ–™å¯¹Llama 2è¿›è¡Œå¢é‡é¢„è®­ç»ƒ
åŒæ—¶ï¼Œæˆ‘ä»¬å°†ä¼šå›´ç»• Llama2-Chinese æ‰“é€ å„ç§å‚ç›´é¢†åŸŸæ¨¡å‹

## æ•ˆæœæ¼”ç¤º

## ğŸ”§ æ¨¡å‹å¾®è°ƒ

æœ¬ä»“åº“ä¸­æä¾›äº†åŸºäºQLoRAçš„å¾®è°ƒä»£ç 

æˆ‘ä»¬çš„è®­ç»ƒä»£ç åŸºäº[FastChat](https://github.com/lm-sys/FastChat)å¼€å‘.æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”¨ä¸¤å¼ A100ï¼ˆ80Gï¼‰è®­ç»ƒToolLLaMA-7b, è®­ç»ƒæ•°æ®æ˜¯æˆ‘ä»¬å·²ç»å¤„ç†å¥½çš„[æ•°æ®]
```bash
export PYTHONPATH=./
deepspeed --master_port=20001 toolbench/train/train_long_seq_lora.py \
    --model_name_or_path huggyllama/llama-7b  \
    --data_path  data/toolllama_G123_dfs_train.json \
    --eval_data_path  data/toolllama_G123_dfs_eval.json \
    --conv_template tool-llama-single-round \
    --bf16 True \
    --output_dir toolllama_lora \
    --num_train_epochs 5 \
    --per_device_train_batch_size 4 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 2 \
    --evaluation_strategy "epoch" \
    --prediction_loss_only \
    --save_strategy "epoch" \
    --save_total_limit 8 \
    --learning_rate 5e-5 \
    --weight_decay 0. \
    --warmup_ratio 0.04 \
    --lr_scheduler_type "cosine" \
    --logging_steps 1 \
    --model_max_length 8192 \
    --gradient_checkpointing True \
    --lazy_preprocess True \    
    --deepspeed ds_configs/stage2.json \
    --report_to none
```

## æ•°æ®æ¸…æ´—
* ä»…ä¸­è‹±æ–‡ï¼šä½¿ç”¨fasttextçš„è¯­è¨€è¯†åˆ«æ¨¡å‹æ¥æŒ‰è¯­è¨€æ ‡è®°å†…å®¹ï¼Œä»…ç•™ä¸‹ä¸­è‹±æ–‡æ•°æ®
* ç½‘ç»œæ•°æ®ï¼šå¤§å¤šæ•°å¼€æ”¾è¯­è¨€æ¨¡å‹ï¼ˆå¦‚Llama 1/2ã€Falconã€T5ã€MPTï¼‰éƒ½æ˜¯åŸºäºé¢„å¤„ç†çš„ç½‘ç»œæ–‡æœ¬çš„ä¸€ä¸ªé‡è¦éƒ¨åˆ†è¿›è¡Œè®­ç»ƒçš„ã€‚
* è´¨é‡è¿‡æ»¤ï¼šç½‘ç»œçˆ¬å–çš„æ•°æ®ä¸­æœ‰å¾ˆå¤§ä¸€éƒ¨åˆ†ä¸é€‚åˆè¯­è¨€æ¨¡å‹è®­ç»ƒï¼ˆä¾‹å¦‚ï¼Œæ ¼å¼ä¸æ­£ç¡®çš„æ–‡æœ¬ã€è‡ªåŠ¨ç”Ÿæˆçš„ç½‘ç«™æ–‡æœ¬ï¼‰ã€‚è¿™äº›é€šå¸¸é€šè¿‡â€œè´¨é‡â€è¿‡æ»¤æ–¹æ³•æ¥ç§»é™¤ï¼Œè¿™é‡Œé€‰æ‹©ä½¿ç”¨ç®€å•çš„å¯å‘å¼æ–¹æ³•å’Œæ­£åˆ™è¡¨è¾¾å¼æ¥è¿‡æ»¤æ®µè½ã€‚è¿™äº›è¿‡æ»¤å™¨çš„æ•ˆæœæ˜¯å»é™¤ä»HTMLè½¬æ¢ä¸ºçº¯æ–‡æœ¬æ—¶äº§ç”Ÿçš„é”™è¯¯ã€‚
* å»é‡ï¼šæœ€è¿‘çš„ç ”ç©¶è¡¨æ˜ï¼Œæ•°æ®å»é‡å¯ä»¥ä½¿è¯­è¨€æ¨¡å‹æ›´æœ‰æ•ˆåœ°è®­ç»ƒã€‚éµå¾ªè¿™ä¸€åŸåˆ™ï¼Œæˆ‘é€‰æ‹©åœ¨æ¯ä¸ªæ¥æºä¸­å»é‡æ•°æ®ã€‚
* å¤šæ ·åŒ–çš„æ¥æºï¼šåƒGPT-Neoæˆ–Pythiaè¿™æ ·çš„æ¨¡å‹ï¼ˆä¸¤è€…éƒ½åœ¨The Pileä¸Šè®­ç»ƒï¼‰å·²ç»æ˜¾ç¤ºäº†åœ¨å¤šæ ·åŒ–çš„æ–‡æ¡£é›†ä¸Šè®­ç»ƒçš„é‡è¦æ€§ï¼Œå¦‚æŠ€æœ¯æ–‡æ¡£æˆ–ç”Ÿç‰©åŒ»å­¦æ–‡ç« ã€‚è¿™é‡Œæˆ‘åŠ å…¥äº†æ›´å¤šçš„ç½‘ç»œSFTæ•°æ®ï¼Œå¦‚InstructionWild

## æ•°æ®å‘å¸ƒ

ä½¿ç”¨ä¸‹é¢é“¾æ¥ä¸‹è½½æˆ‘ä»¬çš„æ•°æ®é›†
- 


## å¢é‡é¢„è®­ç»ƒæ•°æ®

| ç±»å‹                                                       | æè¿°                                                         |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| [CLUECorpus2020](https://github.com/CLUEbenchmark/CLUECorpus2020) | é€šè¿‡å¯¹Common Crawlçš„ä¸­æ–‡éƒ¨åˆ†è¿›è¡Œè¯­æ–™æ¸…æ´—ï¼Œæœ€ç»ˆå¾—åˆ°100GBçš„é«˜è´¨é‡ä¸­æ–‡é¢„è®­ç»ƒè¯­æ–™ï¼Œå¯ç›´æ¥ç”¨äºé¢„è®­ç»ƒã€è¯­è¨€æ¨¡å‹æˆ–è¯­è¨€ç”Ÿæˆä»»åŠ¡ä»¥åŠä¸“ç”¨äºç®€ä½“ä¸­æ–‡NLPä»»åŠ¡çš„å°è¯è¡¨ã€‚ |
| [Wikipedia](https://github.com/goldsmith/Wikipedia)        | ä¸­æ–‡Wikipediaçš„æ•°æ®                                          |
| [MNBVCï¼ˆpartï¼‰](https://github.com/esbatmop/MNBVC)                 | è¶…å¤§è§„æ¨¡ä¸­æ–‡è¯­æ–™é›†ï¼Œä¸ä½†åŒ…æ‹¬ä¸»æµæ–‡åŒ–ï¼Œä¹ŸåŒ…æ‹¬å„ä¸ªå°ä¼—æ–‡åŒ–ç”šè‡³ç«æ˜Ÿæ–‡çš„æ•°æ®ã€‚MNBVCæ•°æ®é›†åŒ…æ‹¬æ–°é—»ã€ä½œæ–‡ã€å°è¯´ã€ä¹¦ç±ã€æ‚å¿—ã€è®ºæ–‡ã€å°è¯ã€å¸–å­ã€wikiã€å¤è¯—ã€æ­Œè¯ã€å•†å“ä»‹ç»ã€ç¬‘è¯ã€ç³—äº‹ã€èŠå¤©è®°å½•ç­‰ä¸€åˆ‡å½¢å¼çš„çº¯æ–‡æœ¬ä¸­æ–‡æ•°æ®ã€‚æ•°æ®å‡æ¥æºäºäº’è”ç½‘æ”¶é›†|

### SFTæ•°æ®

| ç±»å‹                                                       | æè¿°                                                         |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| [ShareChat](https://huggingface.co/datasets/shareAI/ShareGPT-Chinese-English-90k) | ä¸­è‹±æ–‡å¹³è¡ŒåŒè¯­ä¼˜è´¨äººæœºé—®ç­”æ•°æ®é›†ï¼Œè¦†ç›–çœŸå®å¤æ‚åœºæ™¯ä¸‹çš„ç”¨æˆ·æé—®ã€‚ |
| [alpaca-gpt4](https://huggingface.co/datasets/vicgalle/alpaca-gpt4)        | Alpaca-GPT-4 æ˜¯ä¸€ä¸ªä½¿ç”¨ self-instruct æŠ€æœ¯ï¼ŒåŸºäº 175 æ¡ä¸­æ–‡ç§å­ä»»åŠ¡å’Œ GPT-4 æ¥å£ç”Ÿæˆçš„ 50K çš„æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ã€‚                                          |
| [BELLE-data-1.5M](https://github.com/LianjiaTech/BELLE/tree/main/data/1.5M)        | é€šè¿‡self-instructç”Ÿæˆï¼Œä½¿ç”¨äº†ä¸­æ–‡ç§å­ä»»åŠ¡ï¼Œä»¥åŠopenaiçš„text-davinci-003æ¥å£,æ¶‰åŠ175ä¸ªç§å­ä»»åŠ¡|
| [InstructionWild](https://github.com/XueFuzhao/InstructionWild)        | InstructionWild æ˜¯ä¸€ä¸ªä»ç½‘ç»œä¸Šæ”¶é›†è‡ªç„¶æŒ‡ä»¤å¹¶è¿‡æ»¤ä¹‹åä½¿ç”¨è‡ªç„¶æŒ‡ä»¤ç»“åˆ ChatGPT æ¥å£ç”ŸæˆæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†çš„é¡¹ç›®ã€‚ä¸»è¦çš„æŒ‡ä»¤æ¥æºï¼šTwitterã€CookUp.AIã€Github å’Œ Discardã€‚|
| [COIG(part)](https://huggingface.co/datasets/BAAI/COIG)| ä¸€å¥—æ— å®³ã€æœ‰ç”¨ä¸”å¤šæ ·åŒ–çš„ä¸­æ–‡æŒ‡ä»¤è¯­æ–™åº“ï¼ŒåŒ…æ‹¬ä¸€ä¸ªäººå·¥éªŒè¯ç¿»è¯‘çš„é€šç”¨æŒ‡ä»¤è¯­æ–™åº“ã€ä¸€ä¸ªäººå·¥æ ‡æ³¨çš„è€ƒè¯•æŒ‡ä»¤è¯­æ–™åº“ã€ä¸€ä¸ªäººç±»ä»·å€¼å¯¹é½æŒ‡ä»¤è¯­æ–™åº“ã€ä¸€ä¸ªå¤šè½®åäº‹å®ä¿®æ­£èŠå¤©è¯­æ–™åº“å’Œä¸€ä¸ª leetcode æŒ‡ä»¤è¯­æ–™åº“ã€‚|

### å‚ç›´é¢†åŸŸæ•°æ®

| ç±»å‹                                                       | æè¿°                                                         |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| [Chinese medical dialogue data](https://github.com/Toyhom/Chinese-medical-dialogue-data) | ä¸­æ–‡åŒ»ç–—å¯¹è¯æ•°æ®é›†ï¼ŒåŒ…æ‹¬ï¼š<Andriatria_ç”·ç§‘> 94596ä¸ªé—®ç­”å¯¹ <IM_å†…ç§‘> 220606ä¸ªé—®ç­”å¯¹ <OAGD_å¦‡äº§ç§‘> 183751ä¸ªé—®ç­”å¯¹ <Oncology_è‚¿ç˜¤ç§‘> 75553ä¸ªé—®ç­”å¯¹ <Pediatric_å„¿ç§‘> 101602ä¸ªé—®ç­”å¯¹ <Surgical_å¤–ç§‘> 115991ä¸ªé—®ç­”å¯¹ æ€»è®¡ 792099ä¸ªé—®ç­”å¯¹ã€‚ |
| [Huatuo-26M](https://github.com/FreedomIntelligence/Huatuo-26M)        | Huatuo-26M æ˜¯ä¸€ä¸ªä¸­æ–‡åŒ»ç–—é—®ç­”æ•°æ®é›†ï¼Œæ­¤æ•°æ®é›†åŒ…å«äº†è¶…è¿‡2600ä¸‡ä¸ªé«˜è´¨é‡çš„åŒ»ç–—é—®ç­”å¯¹ï¼Œæ¶µç›–äº†å„ç§ç–¾ç—…ã€ç—‡çŠ¶ã€æ²»ç–—æ–¹å¼ã€è¯å“ä¿¡æ¯ç­‰å¤šä¸ªæ–¹é¢ã€‚ |
| [ToolBench](https://github.com/OpenBMB/ToolBench)        | ToolBench åŒ…æ‹¬å•å·¥å…·å’Œå¤šå·¥å…·åœºæ™¯ï¼Œä» RapidAPI ä¸­è·å– 16,000 å¤šä¸ªçœŸå®ä¸–ç•Œçš„APIï¼Œå¹¶æ•´ç†å‡ºæ¶‰åŠè¿™äº›APIçš„çœŸå®ä¸–ç•Œäººç±»æŒ‡ä»¤ã€‚å¤šå·¥å…·åœºæ™¯å¯è¿›ä¸€æ­¥åˆ†ä¸ºç±»åˆ«å†…å¤šå·¥å…·å’Œé›†åˆå†…å¤šå·¥å…·ã€‚ |
| [moss-003-sft-plugin-data](https://github.com/OpenLMLab/MOSS/tree/main/SFT_data/conversations/conversation_with_plugins)        | ä½¿ç”¨çš„æ’ä»¶å¢å¼ºçš„å¤šè½®å¯¹è¯æ•°æ®ï¼ŒåŒ…å«æ”¯æŒæœç´¢å¼•æ“ã€æ–‡ç”Ÿå›¾ã€è®¡ç®—å™¨ã€è§£æ–¹ç¨‹ç­‰å››ä¸ªæ’ä»¶åœ¨å†…çš„çº¦30ä¸‡æ¡å¤šè½®å¯¹è¯æ•°æ®ã€‚ |

### RLHFæ•°æ®

| ç±»å‹                                                       | æè¿°                                                         |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| [GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | è¯¥é¡¹ç›®å¼€æºäº†ç”±GPT4ç”Ÿæˆçš„å¤šç§æ•°æ®é›†ï¼ŒåŒ…æ‹¬é€šè¿‡GPT4ç”Ÿæˆçš„ä¸­è‹±PPOæ•°æ®ï¼Œå¯ä»¥ç”¨äºå¥–åŠ±æ¨¡å‹çš„è®­ç»ƒã€‚ |


## æ¨¡å‹ä¸‹è½½

Metaåœ¨ğŸ¤—Hugging Faceä¸Šæä¾›äº†æ‰€æœ‰æ¨¡å‹çš„ä¸‹è½½é“¾æ¥ï¼šhttps://huggingface.co/meta-llama

### Llama2 æ¨¡å‹

Llama2 é¢„è®­ç»ƒæ¨¡å‹åŒ…å«7Bã€13Bå’Œ70Bä¸‰ä¸ªç‰ˆæœ¬ï¼›Llama2-Chatæ¨¡å‹åŸºäºé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œäº†ç›‘ç£å¾®è°ƒï¼Œå…·å¤‡æ›´å¼ºçš„å¯¹è¯èƒ½åŠ›ã€‚

| æ¨¡å‹åç§°   | ğŸ¤—æ¨¡å‹åŠ è½½åç§°             | ä¸‹è½½åœ°å€                                                     |
| ---------- | ------------------------- | ------------------------------------------------------------ |
| Llama2-7B  | meta-llama/Llama-2-7b-hf  | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-7b-hf)  |
| Llama2-13B | meta-llama/Llama-2-13b-hf | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-13b-hf) |
| Llama2-70B | meta-llama/Llama-2-70b-hf | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-70b-hf) |
| Llama2-7B-Chat  | meta-llama/Llama-2-7b-chat-hf  | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf) |
| Llama2-13B-Chat | meta-llama/Llama-2-13b-chat-hf | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-13b-chat-hf) |
| Llama2-70B-Chat | meta-llama/Llama-2-70b-chat-hf | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/meta-llama/Llama-2-70b-chat-hf) |
| Llama2-13b-Chinese-chat | carlAIwarts/Llama2-13b-Chinese-chat | [æ¨¡å‹ä¸‹è½½](https://huggingface.co/carlAIwarts/Llama2-13b-Chinese-chat) |

### æ¨¡å‹æ¨ç†

**å¸¸ç”¨ç”Ÿæˆ**
```python
from transformers import LlamaForCausalLM, LlamaTokenizer

model_path = 'carlAIwarts/Llama2-13b-Chinese-chat'

tokenizer = LlamaTokenizer.from_pretrained(model_path)
model = LlamaForCausalLM.from_pretrained(model_path)
prompt = "ç”¨ä¸­æ–‡ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
input_ids = tokenizer(prompt, return_tensors="pt").input_ids
gen_tokens = model.generate(
    input_ids,
    do_sample=True,
    temperature=0.6,
    max_length=512,
)
gen_text = tokenizer.batch_decode(gen_tokens)[0]
print(gen_text)
```

**æµå¼ç”Ÿæˆ**
```python
from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer

model_path = 'carlAIwarts/Llama2-13b-Chinese-chat'

tokenizer = LlamaTokenizer.from_pretrained(model_path)
model = LlamaForCausalLM.from_pretrained(model_path)

streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)
prompt = "ç”¨ä¸­æ–‡ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
generate_ids = model.generate(tokenizer(prompt, return_tensors='pt').input_ids.cuda(), max_new_tokens=4096, streamer=streamer)
```

### Gradioå¿«é€Ÿæ­å»ºé—®ç­”å¹³å°

- [ ] åŸºäºgradioæ­å»ºçš„é—®ç­”ç•Œé¢ï¼Œå®ç°æµå¼çš„è¾“å‡º

## ğŸ† æ¨¡å‹è¯„æµ‹
ä¸ºäº†èƒ½å¤Ÿæ›´åŠ æ¸…æ™°åœ°äº†è§£Llama2æ¨¡å‹çš„ä¸­æ–‡é—®ç­”èƒ½åŠ›ï¼Œæˆ‘ä»¬å®ç°äº†å¯¹åº”çš„è¯„ä¼°æ•°æ®å’Œä»£ç 

| ç±»å‹                                                       | æè¿°                                                         |
| ---------------------------------------------------------- | ------------------------------------------------------------ |
| [C-Eval](https://github.com/SJTU-LIT/ceval) | æ„é€ äº†ä¸€ä¸ªè¦†ç›–äººæ–‡ï¼Œç¤¾ç§‘ï¼Œç†å·¥ï¼Œå…¶ä»–ä¸“ä¸šå››ä¸ªå¤§æ–¹å‘ï¼Œ52 ä¸ªå­¦ç§‘ï¼ˆå¾®ç§¯åˆ†ï¼Œçº¿ä»£ â€¦ï¼‰ï¼Œä»ä¸­å­¦åˆ°å¤§å­¦ç ”ç©¶ç”Ÿä»¥åŠèŒä¸šè€ƒè¯•ï¼Œä¸€å…± 13948 é“é¢˜ç›®çš„ä¸­æ–‡çŸ¥è¯†å’Œæ¨ç†å‹æµ‹è¯•é›†ã€‚æ­¤å¤–è¿˜ç»™å‡ºäº†å½“å‰ä¸»æµä¸­æ–‡LLMçš„è¯„æµ‹ç»“æœã€‚ |
| [MMCU](https://github.com/Felixgithub2017/MMCU) | è¯¥é¡¹ç›®æä¾›å¯¹ä¸­æ–‡å¤§æ¨¡å‹è¯­ä¹‰ç†è§£èƒ½åŠ›çš„æµ‹è¯•ï¼Œè¯„æµ‹æ–¹å¼ã€è¯„æµ‹æ•°æ®é›†ã€è¯„æµ‹è®°å½•éƒ½å…¬å¼€ï¼Œç¡®ä¿å¯ä»¥å¤ç°ã€‚è¯¥é¡¹ç›®æ—¨åœ¨å¸®åŠ©å„ä½ç ”ç©¶è€…ä»¬è¯„æµ‹è‡ªå·±çš„æ¨¡å‹æ€§èƒ½ï¼Œå¹¶éªŒè¯è®­ç»ƒç­–ç•¥æ˜¯å¦æœ‰æ•ˆã€‚ |
| [MMLU](https://github.com/hendrclycks/test) | åŒ…å« 57 ä¸ªå¤šé€‰ä»»åŠ¡çš„è‹±æ–‡è¯„æµ‹æ•°æ®é›†ï¼Œæ¶µç›–äº†åˆç­‰æ•°å­¦ã€ç¾å›½å†å²ã€è®¡ç®—æœºç§‘å­¦ã€æ³•å¾‹ç­‰ï¼Œéš¾åº¦è¦†ç›–é«˜ä¸­æ°´å¹³åˆ°ä¸“å®¶æ°´å¹³ |

## ğŸ“š Llamaè®ºæ–‡
* [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971)
* [Llama 2: Open Foundation and Fine-Tuned Chat Models](https://arxiv.org/abs/2307.09288)

## ğŸ¤” å…¥ç¾¤äº¤æµ

åŠ å…¥å¾®ä¿¡ç¾¤è®¨è®ºï¼›å›¾ç‰‡è¿‡æœŸçš„è¯ä¹Ÿæ¬¢è¿åŠ æˆ‘çš„å¾®ä¿¡ï¼šcarl_like_travel

<p align="center" width="60%">
<img src="./assets/wechat.jpeg" alt="Wechat" style="width: 60%; display: block; margin: auto;">
</p>
